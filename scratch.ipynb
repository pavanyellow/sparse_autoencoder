{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled automatic differentiation\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import torch\n",
    "from circuitsvis.attention import attention_heads\n",
    "from fancy_einsum import einsum\n",
    "from IPython.display import HTML, IFrame\n",
    "from jaxtyping import Float\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import ActivationCache, HookedTransformer\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "print(\"Disabled automatic differentiation\")\n",
    "\n",
    "def imshow(tensor, **kwargs):\n",
    "    px.imshow(\n",
    "        utils.to_numpy(tensor),\n",
    "        color_continuous_midpoint=0.0,\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        **kwargs,\n",
    "    ).show()\n",
    "\n",
    "\n",
    "def line(tensor, **kwargs):\n",
    "    px.line(\n",
    "        y=utils.to_numpy(tensor),\n",
    "        **kwargs,\n",
    "    ).show()\n",
    "\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(\n",
    "        y=y,\n",
    "        x=x,\n",
    "        labels={\"x\": xaxis, \"y\": yaxis, \"color\": caxis},\n",
    "        **kwargs,\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"gpt2-small\", center_writing_weights= False)\n",
    "\n",
    "# Get the default device used\n",
    "device: torch.device = utils.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4532, 1024])\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"NeelNanda/c4-10k\", split=\"train\") # 4M tokens\n",
    "tokenized_data = utils.tokenize_and_concatenate(data, model.tokenizer, max_length=1024)\n",
    "tokenized_data = tokenized_data.shuffle(42)\n",
    "all_tokens = tokenized_data[\"tokens\"]\n",
    "print(all_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4532, 1024])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>�t really as bad as the Jews want you to believe.\\nWe will never know the name of each and every victim, but photographic evidence and first-hand stories make it clear that something extensive and quite barbaric occurred. And yet, apparently otherwise rational people deny it.\\nMaybe their blindness is psychosomatic; maybe it grows out of prejudice.\\nMany more people deny the animal holocaust. They just can’t see the suffering apparently, suffering on a magnitude that dwarfs the combined evils we have perpetrated on ourselves.\\nCertain skills are considered key signs of higher mental abilities: good memory, a grasp of grammar and symbols, self-awareness, understanding others\\' motives, imitating others, and being creative. Bit by bit, in ingenious experiments, researchers have documented these talents in other species, gradually chipping away at what we thought made human beings distinctive while offering a glimpse of where our own abilities came from. Minds of their Own. National Geographic. 2008.\\nSigns of higher mental ability in animals are cause for great alarm.\\nWe hurt and kill billions of animals every year. Literally. Billions. To a growing number of people, particularly to those who understand that the fundamental idea behind human rights is that our similarities matter immeasurably more that our differences, it is these signs of higher mental ability, our similarities, which make the animals’ plight so immediately important.\\n[Irene] Pepperberg carried Alex [(1976 - 2007), an African grey parrot] on her arm to a tall wooden perch in the middle of the room. She then retrieved a green key and a small green cup from a basket on a shelf. She held up the two items to Alex\\'s eye.\\n“Shape,” Alex said. His voice had the digitized sound of a cartoon character. Since parrots lack lips (another reason it was difficult for Alex to pronounce some sounds, such as ba), the words seemed to come from the air around him, as if a ventriloquist were speaking. But the words—and what can only be called the thoughts—were entirely his.”Minds of their Own. National Geographic. 2008.\\nHow can anyone deny the animal holocaust? Denial probably grows from three sources: mental deficit, ignorance, or bigotry. Maybe people really don’t notice that their dog is a someone. Maybe people really can’t imagine the pig behind the chop. Maybe people like feeling superior.\\n... A whole range of animal studies now suggest that the roots of cognition are deep, widespread, and highly malleable. Minds of their Own. National Geographic. 2008.\\nThe animal holocaust must be main-stream science’s greatest failure and is likely to remain so unless we scorch the globe in a nuclear conflagration. Discoveries about the similarity between humans and other species have demolished all prior claims about animals being unfeeling brutes with little if any sense of self. These claims were used repeatedly as defenses against critics’ concerns. And yet, science has said little to alert the public to the ethical implications of these discoveries, and worse, justification for vivisection is often now based on precisely these similarities – an animal model of depression, for example, is valuable they claim, because our suffering is of a like kind.\\nPeople were surprised to discover that chimpanzees make tools,\" said Alex Kacelnik, a behavioral ecologist at Oxford University, referring to the straws and sticks chimpanzees shape to pull termites from their nests. \"But people also thought, \\'Well, they share our ancestry—of course they\\'re smart.\\' Now we\\'re finding these kinds of exceptional behaviors in some species of birds. But we don\\'t have a recently shared ancestry with birds. Their evolutionary history is very different; our last common ancestor with all birds was a reptile that lived over 300 million years ago.\\n\"This is not trivial,\" Kacelnik continued. \"It means that evolution can invent similar forms of advanced intelligence more than once—that it\\'s not something reserved only for primates or mammals.\"Minds of their Own. National Geographic. 2008.\\nHow much like us do we need to discover animals to be before we are able to see the horrors that are occurring so vividly around us all the time?\\nAnd what are the implications for those who see the animal holocaust as it is? What is the proper response?\\nShould the response change over time?\\nAt least 2500 years ago, people were arguing that the obvious similarities between us and other animals meant that eating them was immoral. Legislation providing some protection for animals has been passing in various countries since the late 1700s.\\nAnd yet, little substantive effect can be seen. What should someone do in the face of the animal holocaust in light of the long history of the failure to stop it?\\nOne way to answer this question is to ask yourself what you think you might have done if you were living in Germany during the Holocaust'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_string(all_tokens[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = model.run_with_cache(all_tokens[200:201], remove_batch_dim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_token = model(all_tokens[200:201], return_type=\"loss\", loss_per_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 50257])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m, in \u001b[0;36mline\u001b[0;34m(tensor, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mline\u001b[39m(tensor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     \u001b[43mpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/interp/lib/python3.11/site-packages/plotly/basedatatypes.py:3410\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3377\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3378\u001b[0m \u001b[38;5;124;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[1;32m   3379\u001b[0m \u001b[38;5;124;03mspecified by the renderer argument\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3406\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m   3407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3408\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[0;32m-> 3410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/interp/lib/python3.11/site-packages/plotly/io/_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         )\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "line(torch.randn(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_lens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
